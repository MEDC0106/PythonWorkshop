


# Run this cell before you attempt the exercises
%matplotlib inline
import matplotlib.pyplot as plt
import seaborn as sns
import pandas as pd
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import ConfusionMatrixDisplay, confusion_matrix, RocCurveDisplay, roc_curve, auc
from sklearn.model_selection import train_test_split
from sklearn.svm import SVC
from sklearn.ensemble import RandomForestClassifier





# Read the CSV file and check the diagnostic measurements recorded for each patient
data_path = 'https://raw.githubusercontent.com/MEDC0106/PythonWorkshop/main/workshop/session_3/data/diabetes.csv'
df = pd.read_csv(data_path)

print('\033[1ma)\033[0m')
print("Diagnostic measurements recorded for each patient:")
print(df.columns)

print('\n\033[1mb)\033[0m')
print("Data type of each measurement:")
print(df.dtypes)

print('\n\033[1mc)\033[0m')
print("Total number of patients assessed:", len(df))





print('\033[1ma)\033[0m')
print("Number of records before removing entries with unusual values:", len(df))
# Display a summary of the dataset to identify any potentially unreliable values (e.g., zeros in measurements that shouldn't be zero)
print("Summary statistics of the dataset:")
print(df.describe())

print('\n\033[1mb)\033[0m')
# Here we identify and remove rows where certain columns have zero values, which may be biologically implausible.
columns_to_check = ['Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI']
for column in columns_to_check:
    df = df[df[column] != 0]

# Display the number of records after removing unreliable entries
print("Number of records after removing entries with unusual values:", len(df))





# Count the number of patients with and without diabetes
outcome_counts = df['Outcome'].value_counts()

print("Number of patients with and without diabetes:")
print(outcome_counts)

# Plot the results
plt.figure(figsize=(8, 6))
outcome_counts.plot(kind='bar')
plt.title('Number of patients with and without diabetes')
plt.xlabel('Diabetes diagnosis (0 = No, 1 = Yes)')
plt.ylabel('Number of patients')
plt.xticks([0, 1], ['Without siabetes', 'With diabetes'], rotation=0)
plt.show()

# Check if the data is balanced
# If the difference between the two counts is less than or equal to 10% of the dataset, the data is considered balanced
is_balanced = abs(outcome_counts[0] - outcome_counts[1]) <= 0.1 * len(df)
print("\nIs the data balanced? ", "Yes" if is_balanced == True else "No")





df.hist(figsize=[8, 8])
plt.suptitle("Histograms of diagnostic measurements")
plt.show()





# Load the dataset
data_path = 'https://raw.githubusercontent.com/MEDC0106/PythonWorkshop/main/workshop/session_3/data/diabetes.csv'
df = pd.read_csv(data_path)

# Calculate the correlation between 'BMI' and 'Glucose'
correlation = df['BMI'].corr(df['Glucose'])
print(f"Correlation between BMI and Glucose: {correlation:.2f}")

# Clean up the data
columns_to_check = ['Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI']
for column in columns_to_check:
    df = df[df[column] != 0]

# Create a scatter plot
plt.figure(figsize=(8, 6))
plt.scatter(df['Glucose'], df['BMI'], alpha=0.5)
plt.title('Scatter plot of BMI vs. Glucose')
plt.xlabel('Glucose')
plt.ylabel('BMI')
plt.grid(True)
plt.show()

if correlation <0.5:
    print('No correlation!')
else:
    print('Some correlation observed!')








# Calculate the correlation matrix
correlation_matrix = df.corr()

# Find the two features with the highest correlation
# We use `.unstack()` to convert the matrix to a Panda Series and `.dropna()` to remove self-correlations (1.0)
correlation_pairs = correlation_matrix.unstack().dropna()

# Remove self-correlations
correlation_pairs = correlation_pairs[correlation_pairs < 1]

# Sort correlations in descending order and get the highest pair (first row)
sorted_correlation_pairs = correlation_pairs.sort_values(ascending=False)
highest_correlation = sorted_correlation_pairs.iloc[0]

# Display the result
print("The two features with the highest correlation are:")
print(f"{sorted_correlation_pairs.index[0][0]} and {sorted_correlation_pairs.index[0][1]} with a correlation of {highest_correlation:.2f}")





# Calculate the correlation of each feature with the Outcome column
outcome_correlation = df.corr()['Outcome'].drop('Outcome')

# Find the feature with the highest correlation with Outcome
highest_corr_feature = outcome_correlation.idxmax()
highest_corr_value = outcome_correlation.max()

# Display the result
print(f"The feature with the highest correlation with the Outcome ('diabetes' diagnosis) is '{highest_corr_feature}' with a correlation of {highest_corr_value:.2f}")








# Separate features and target
X = df.drop(columns=['Outcome'])
y = df['Outcome']

# Split into 80% train and 20% test
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)

# Check the shapes of the splits
print("Training set shape:", X_train.shape)
print("Testing set shape:", X_test.shape)
print("Training target shape:", y_train.shape)
print("Testing target shape:", y_test.shape)





from sklearn.preprocessing import StandardScaler

# Initialise the scaler
scaler = StandardScaler()

# Scale the training features
X_train_scaled = scaler.fit_transform(X_train)

# Apply the same transformation to the testing features
X_test_scaled = scaler.transform(X_test)

# No output is expected from this cell





# Define range of neighbours to test
neighbors_range = range(1, 21)
accuracies = []

# Test different values of `n_neighbors` to find best accuracy
for n in neighbors_range:
    knn = KNeighborsClassifier(n_neighbors=n)
    knn.fit(X_train_scaled, y_train)
    y_pred_train = knn.predict(X_train_scaled)
    accuracies.append((y_pred_train == y_train).mean())  # Manual accuracy calculation

# Find the optimal number of neighbours
best_n = neighbors_range[accuracies.index(max(accuracies))]
print(f"Best `n_neighbors` for accuracy: {best_n}")

# Train the final model with best n_neighbors
knn_best = KNeighborsClassifier(n_neighbors=best_n)
knn_best.fit(X_train_scaled, y_train)

# Predict on the test set
y_pred = knn_best.predict(X_test_scaled)

# Calculate accuracy manually
accuracy = (y_pred == y_test).mean()
print(f"Accuracy: {accuracy}")

# Construct a confusion matrix (NumPy array)
c_m = confusion_matrix(y_true=y_test, y_pred=y_pred)

# Plot the confusion matrix
ConfusionMatrixDisplay(c_m, display_labels=['Non-diabetic', 'Diabetic']).plot(cmap='Blues');

# Calculate ROC curve and AUC
fpr, tpr, _ = roc_curve(y_test, y_pred)
roc_auc = auc(fpr, tpr)

# Plot ROC curve
RocCurveDisplay(fpr=fpr, tpr=tpr, roc_auc=roc_auc, estimator_name='KNN').plot();





# Train and evaluate an SVM model
svm_model = SVC(probability=True)  # Enable probability to get ROC-AUC
svm_model.fit(X_train_scaled, y_train)
y_pred_svm = svm_model.predict(X_test_scaled)

# Calculate accuracy
accuracy_svm = (y_pred_svm == y_test).mean()
print(f"SVM accuracy: {accuracy_svm:.2f}")

# Confusion matrix
conf_matrix_svm = confusion_matrix(y_test, y_pred_svm)
ConfusionMatrixDisplay(conf_matrix_svm, display_labels=['Non-diabetic', 'Diabetic']).plot(cmap='Blues');
plt.title("SVM confusion matrix")

# ROC curve and AUC
fpr_svm, tpr_svm, _ = roc_curve(y_test, svm_model.predict_proba(X_test_scaled)[:, 1])
roc_auc_svm = auc(fpr_svm, tpr_svm)

# Plot ROC curve for SVM
plt.figure(figsize=(8, 6))
plt.plot(fpr_svm, tpr_svm, label=f'SVM (AUC = {roc_auc_svm:.2f})')
plt.plot([0, 1], [0, 1], '--', color='grey')
plt.xlabel('False positive rate')
plt.ylabel('True positive rate')
plt.title('SVM ROC curve')
plt.legend()
plt.show()

# Train and evaluate a Random Forest model
rf_model = RandomForestClassifier(n_estimators=100)
rf_model.fit(X_train_scaled, y_train)
y_pred_rf = rf_model.predict(X_test_scaled)

# Calculate accuracy
accuracy_rf = (y_pred_rf == y_test).mean()
print(f"Random Forest accuracy: {accuracy_rf:.2f}")

# Confusion matrix
conf_matrix_rf = confusion_matrix(y_test, y_pred_rf)
ConfusionMatrixDisplay(conf_matrix_rf, display_labels=['Non-diabetic', 'Diabetic']).plot(cmap='Blues');
plt.title("Random Forest confusion matrix")

# ROC Curve and AUC
fpr_rf, tpr_rf, _ = roc_curve(y_test, rf_model.predict_proba(X_test_scaled)[:, 1])
roc_auc_rf = auc(fpr_rf, tpr_rf)

# Plot ROC curve for Random Forest
plt.figure(figsize=(8, 6))
plt.plot(fpr_rf, tpr_rf, label=f'Random Forest (AUC = {roc_auc_rf:.2f})')
plt.plot([0, 1], [0, 1], '--', color='grey')
plt.xlabel('False positive rate')
plt.ylabel('True positive rate')
plt.title('Random Forest ROC curve')
plt.legend()
plt.show()
