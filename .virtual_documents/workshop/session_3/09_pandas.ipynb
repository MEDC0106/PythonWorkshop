


import pandas as pd

# Create a Pandas Series
s = pd.Series([1.0, 2.0, 3.0, 5.0])

# Display the Series
s





# This is our dictionary containing the raw data
data = {
    'PatientID': [556785, 998764, 477822, 678329, 675859],
    'Gender': ['M', 'F', 'M', 'M', 'F'],
    'Age': [19, 38, 54, 22, 41],
    'Outcome': ['Negative', 'Positive', 'Positive', 'Negative', 'Negative']
}

# We can now construct a DataFrame
df = pd.DataFrame(data)
df  # Show the data





# Display the first three rows
df.head(n=3)


# Display the last two rows
df.tail(n=2)





gender_column = df['Gender']
gender_column





age_column = df.Age
age_column





cv_data_path = 'https://raw.githubusercontent.com/MEDC0106/PythonWorkshop/main/workshop/session_3/data/data_2021-Oct-31.csv'  # This is the path to our data

cv_data = pd.read_csv(cv_data_path)
cv_data.head(n=10)











cv_data.info()





cv_data.shape





duplicated = pd.concat([cv_data, cv_data])  # Here we have copied the data and added it to itself
duplicated.shape





duplicated = duplicated.drop_duplicates()
duplicated.shape








import random

n_rows = len(cv_data)  # Get the number of rows in the `cv_data` DataFrame

# Create a list with 20% None values and 80% ones
nulls_or_ones = []
for _ in range(n_rows):
    if random.random() < 0.2:  # 20% chance of None
        nulls_or_ones.append(None)
    else:
        nulls_or_ones.append(1)

print("Prepared a random list of length:", len(nulls_or_ones))
print("Is the first value null?", pd.isna(nulls_or_ones[0]))  # Check if the first value is None





cv_data['RandomData'] = nulls_or_ones  # Make a colum called 'RandomData'
cv_data.head(10)





cv_data.info()





cv_data.isna().sum()





# First let's remove rows with null values
remove_rows = cv_data.dropna()
remove_rows.head(10)


remove_rows.shape





cv_data.dropna(axis=1, inplace=True)  # We can do it inplace since we do not care about this column
cv_data.head(10)


cv_data.shape





cv_data.describe()





cv_data.areaName.describe()





cv_data.areaName.unique()





cv_data.areaName.value_counts()





type(cv_data['areaName'])





type(cv_data[['areaName']])





selection = cv_data[['areaName', 'areaCode']]
type(selection)





cv_data.loc[222]  # Return the row with index 222





cv_data.loc[222:226]





ind = cv_data['areaName'] == 'Wales'  # Creates a Boolean Series
ind.tail(5)  # Displays the last 5 values of the Boolean Series





wales_data = cv_data[ind]
wales_data.head(5)





wales_data = cv_data[cv_data['areaName'] == 'Wales']
wales_data.head(5)





# Select rows where number of reported positives is less than 100
cv_data[cv_data['newCasesByPublishDate'] < 100].head(5)





# Count dates in England where numer of reported positives is more than 10,000
cv_data[(cv_data['areaName'] == 'England') & (cv_data['newCasesByPublishDate'] > 10000)].shape





cv_data.newCasesByPublishDate / 100  # Divides a column by 100 and returns a Pandas Series





cv_data.newCasesByPublishDate + cv_data.cumCasesByPublishDate





cv_data['Rubbish'] = cv_data.newCasesByPublishDate * 0.3 / cv_data.cumCasesByPublishDate
cv_data.head(5)





print(cv_data.newCasesByPublishDate.mean())
print(cv_data.newCasesByPublishDate.std())  # Standard deviation





def categorise_cases(x):
    if x >= 10000:
        return 'High'
    elif x <= 200:
        return 'Low'
    else:
        return 'Medium'

# No output is expected from this cell





cv_data['Category'] = cv_data['newCasesByPublishDate'].apply(categorise_cases)
cv_data





cv_data['newCategory'] = cv_data['newCasesByPublishDate'].apply(lambda x: 'Red' if x >= 20000 else 'Amber')
cv_data





cv_data['date'] = pd.to_datetime(cv_data['date'])
cv_data.info()





# Let's select data between the 20th and the 30th October 2021 and restrict it to England
selection = cv_data[(cv_data.date.between('2021-10-20','2021-10-30')) & (cv_data.areaName == 'England')]
selection





scotland_data = cv_data[cv_data.areaName == 'Scotland']
scotland_data





scotland_data.set_index('date', inplace=True)
scotland_data








scotland_data.sort_index(inplace=True)
scotland_data  # Show the data in time-ascending order





scotland_data.loc['2021-10-20':'2021-10-30']





resampled = scotland_data.resample(rule='10d')['newCasesByPublishDate'].mean()
resampled





scotland_data['rollingAvgTenDay'] = scotland_data.rolling(10)['newCasesByPublishDate'].mean()
scotland_data





# We also add this 'Jupyter magic' to display plots in the notebook
%matplotlib inline
import matplotlib.pyplot as plt

# No output is expected from this cell





scotland_data.newCasesByPublishDate.plot();  # Adding a semicolon is preferred in Jupyter





# Select a time window (1-month)
window = scotland_data['2021-09-30':'2021-10-30']

window.newCasesByPublishDate.plot.box();





scotland_data.newCasesByPublishDate.plot(figsize=(8, 4));  # Also specify the size
scotland_data.rollingAvgTenDay.plot();
plt.legend();  # We can also add a legend





figure = scotland_data.newCasesByPublishDate.plot(figsize=(8, 4)).get_figure()
figure.savefig('Scotland.png');



